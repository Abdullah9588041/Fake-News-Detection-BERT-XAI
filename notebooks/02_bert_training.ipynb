{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11219b60",
   "metadata": {},
   "source": [
    "# BERT Model Training\n",
    "## Explainable Fake News Detection using Transformer-based Language Models\n",
    "\n",
    "**Student Name:** Abdullah  \n",
    "**Reg Number:** M24F0044DS009  \n",
    "**Course:** Natural Language Processing  \n",
    "\n",
    "### Objective\n",
    "The objective of this notebook is to fine-tune a pre-trained BERT model for binary fake news classification using labeled news text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e29034ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch scikit-learn tqdm pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3f2c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1782b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "949f9f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "bed0aaab-b32e-4a58-a065-85b5b675d898",
       "rows": [
        [
         "0",
         "phil robertson of duck dynasty has endorsed donald trump and weighs in on the two hottest topics on trump",
         "0"
        ],
        [
         "1",
         "san francisco ap — apple penalized ceo tim cook for the iphone maker’s first sales slump in years with a percent pay cut advertisement",
         "1"
        ],
        [
         "2",
         "if we use tax increment financing funding thats going to take funds from the general fund for pinellas county as it will take funds from the general fund for the city of st pete",
         "0"
        ],
        [
         "3",
         "roughly georgians or about percent of the states residents have gone through a background check to legally obtain a georgia weapons carry license",
         "1"
        ],
        [
         "4",
         "stunned that did not concede if pulled that people would go bananas",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phil robertson of duck dynasty has endorsed do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>san francisco ap — apple penalized ceo tim coo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if we use tax increment financing funding that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roughly georgians or about percent of the stat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stunned that did not concede if pulled that pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  phil robertson of duck dynasty has endorsed do...      0\n",
       "1  san francisco ap — apple penalized ceo tim coo...      1\n",
       "2  if we use tax increment financing funding that...      0\n",
       "3  roughly georgians or about percent of the stat...      1\n",
       "4  stunned that did not concede if pulled that pe...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/shorttextpreprocessedtrain.csv\")\n",
    "test_df = pd.read_csv(\"../data/shorttextpreprocessedtest.csv\")\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8680e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    train_df['text'],\n",
    "    train_df['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df['label']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2411c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cca3560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(\n",
    "    list(train_texts),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128\n",
    ")\n",
    "\n",
    "val_encodings = tokenizer(\n",
    "    list(val_texts),\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16417475",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79719f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FakeNewsDataset(train_encodings, train_labels)\n",
    "val_dataset = FakeNewsDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ef74bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d8474fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='binary'\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6631eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"../results/logs\",\n",
    "    load_best_model_at_end=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "454eafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24dc3702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 500/3801 [58:53<5:32:11,  6.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2531, 'grad_norm': 5.093451499938965, 'learning_rate': 1.736911339121284e-05, 'epoch': 0.39}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 1000/3801 [1:55:03<6:23:55,  8.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2168, 'grad_norm': 2.3349204063415527, 'learning_rate': 1.473822678242568e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 33%|███▎      | 1267/3801 [2:35:17<4:14:43,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22040127217769623, 'eval_accuracy': 0.9001578531965272, 'eval_precision': 0.6874172185430464, 'eval_recall': 0.6577946768060836, 'eval_f1': 0.672279792746114, 'eval_runtime': 535.9446, 'eval_samples_per_second': 9.456, 'eval_steps_per_second': 0.591, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1500/3801 [3:02:14<4:18:36,  6.74s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1925, 'grad_norm': 12.228032112121582, 'learning_rate': 1.2107340173638518e-05, 'epoch': 1.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2000/3801 [4:08:09<4:56:11,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1576, 'grad_norm': 11.552817344665527, 'learning_rate': 9.476453564851356e-06, 'epoch': 1.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 2500/3801 [5:10:12<2:43:50,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1453, 'grad_norm': 11.414710998535156, 'learning_rate': 6.845566956064194e-06, 'epoch': 1.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 67%|██████▋   | 2534/3801 [5:21:55<2:05:43,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2715437710285187, 'eval_accuracy': 0.904301499605367, 'eval_precision': 0.6711711711711712, 'eval_recall': 0.7553865652724968, 'eval_f1': 0.7107930828861061, 'eval_runtime': 485.8606, 'eval_samples_per_second': 10.431, 'eval_steps_per_second': 0.652, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 3000/3801 [6:23:39<1:16:46,  5.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1065, 'grad_norm': 0.38320186734199524, 'learning_rate': 4.214680347277033e-06, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 3500/3801 [7:16:09<32:01,  6.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0912, 'grad_norm': 8.831109046936035, 'learning_rate': 1.5837937384898713e-06, 'epoch': 2.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 3801/3801 [7:54:13<00:00,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3671300709247589, 'eval_accuracy': 0.8983820047355959, 'eval_precision': 0.6473118279569893, 'eval_recall': 0.7629911280101395, 'eval_f1': 0.7004072134962188, 'eval_runtime': 457.4326, 'eval_samples_per_second': 11.079, 'eval_steps_per_second': 0.693, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3801/3801 [7:54:26<00:00,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 28466.4007, 'train_samples_per_second': 2.136, 'train_steps_per_second': 0.134, 'train_loss': 0.1594156592935363, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3801, training_loss=0.1594156592935363, metrics={'train_runtime': 28466.4007, 'train_samples_per_second': 2.136, 'train_steps_per_second': 0.134, 'total_flos': 3218388818049360.0, 'train_loss': 0.1594156592935363, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ad67a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/bert_fake_news_model\\\\tokenizer_config.json',\n",
       " '../models/bert_fake_news_model\\\\special_tokens_map.json',\n",
       " '../models/bert_fake_news_model\\\\vocab.txt',\n",
       " '../models/bert_fake_news_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"../models/bert_fake_news_model\")\n",
    "tokenizer.save_pretrained(\"../models/bert_fake_news_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67bfef",
   "metadata": {},
   "source": [
    "## Training Summary\n",
    "\n",
    "- A pre-trained BERT-base model was successfully fine-tuned for fake news classification.\n",
    "- The model learned contextual representations of news text.\n",
    "- Validation metrics indicate effective learning.\n",
    "- The trained model has been saved for further evaluation and explainability analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6a4040",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
